# ü§ñ Shared Q-Learning<br>Based Iterative Controller Design
# 1Ô∏è‚É£ Method
This repository integrates ***multi-agent shared Q-Learning*** for grid-based path planning with an offline, ***iterative PD gain tuning*** scheme for accurate path tracking by multiple Franka Emika Panda manipulators in ***PyBullet***.
Agents periodically share the best-performing Q-table to accelerate learning; on the control side, PD gains (Kp, Kd) are tuned offline using RMSE as the performance metric. The framework decouples learning (planning) from control (tracking), which eliminates online optimization during control runtime and simplifies deployment.
****
reference
# 2Ô∏è‚É£ Getting Started
## Required Packages
- Python 3.10.12
- 
  ‚úÖ numpy

  ‚úÖ matplotlib

  ‚úÖ pybullet 3.2.7
## Installation
```bash
git clone <your-repo-url>.git
cd <your-repo-name>
```
## Install Python dependencies (e.g., via pip)
### Quick
```bash
pip install --upgrade pip
pip install numpy pybullet pybullet_data matplotlib
```
### Recommended (virtual environment)
```bash
python3 -m venv .venv
source .venv/bin/activate      

pip install --upgrade pip
pip install numpy pybullet pybullet_data matplotlib
```
# 3Ô∏è‚É£ Repository Structure
- MPC_Panda/
  - common/
      - \_\_init\_\_.py
      - gridworld_render.py
      - gridworld.py
      - utils.py
  - q_learning/
      - \_\_init\_\_.py
      - train_q_learning.py
      - extract_path.py
  - kp_then_kd/
      - 01_tune_kp.py
      - 02_tune_kd.py
      - coord_to_xyz.py
      - panda_env.py
  - kd_then_kp/
      - 01_tune_kd.py
      - 02_tune_kp.py
      - coord_to_xyz.py
      - panda_env.py
  - README.md
