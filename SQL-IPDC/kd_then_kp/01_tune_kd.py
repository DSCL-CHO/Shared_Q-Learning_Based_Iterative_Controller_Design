import os, sys; sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
import numpy as np
import matplotlib.pyplot as plt
from kd_then_kp.panda_env import MultiPandaEnv
from common.gridworld import GridWorld
from kd_then_kp.coord_to_xyz import coord_to_xyz

# -----------------------------
# ì‹¤í—˜ ì„¤ì •
robot_n = 9   # ì¼ë ¬ ë°°ì¹˜
kp = 400
init_range = (100, 500)#Kd ì´ˆê¸° ë²”ìœ„
kx_ratio = 0.4            # ë‹¤ìŒ í›„ë³´ ë²”ìœ„ ë¹„ìœ¨
conv_thresh = 0.01    # RMSE ë³€í™” ìˆ˜ë ´ ê¸°ì¤€
max_iter = 10

# ë¡œë´‡ ë°°ì¹˜ ìœ„ì¹˜ (ì¼ë ¬ ë°°ì¹˜)
x_offsets = [i *0.8 for i in range(robot_n)]

# ê²½ë¡œ ë¡œë“œ
path = np.load("saved_models/best_path.npy", allow_pickle=True)


# -----------------------------
def run_simulation(kd_list, iteration):
    env = MultiPandaEnv(num_robots=robot_n, gui=False,
                        x_offsets=x_offsets, 
                        kd_list=kd_list, 
                        kp_list=[kp]*robot_n)
    gw = GridWorld()

    # # ê²©ì ë°°ê²½ì€ ë¡œë´‡ 0ë²ˆ ìœ„ì¹˜ì— í•œ ë²ˆë§Œ ìƒì„±
    # env.render_grid_overlay(x_offset=0, grid_shape=gw.shape,
    #                         reward_map=gw.reward_map,
    #                         wall_states=gw.wall_states,
    #                         goal_state=gw.goal_state)
    # ëª¨ë“  ë¡œë´‡ ìœ„ì¹˜ì— ê²©ì ë°°ê²½ ìƒì„±
    # for x in x_offsets:

    #     env.render_grid_overlay(
    #         x_offset=x,
    #         grid_shape=gw.shape,
    #         reward_map=gw.reward_map,
    #         wall_states=gw.wall_states,
    #         goal_state=gw.goal_state
    #     )


    for coord in path:
        pos_list = [coord_to_xyz(coord, origin=(x, -0.1, 0.6)) for x in x_offsets]
        
        env.move_all(pos_list, steps=2000)
    
    # for i in range(robot_n):
    #      plt.plot(env.errors[i], label=f"Robot {i+1} (Kd={kd_list[i]})")

    # plt.title(f"Iteration {iteration+1} - EE Position Error")
    # plt.xlabel("Step")
    # plt.ylabel("L2 Error")
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.show()


    # RMSE ê³„ì‚°
    rmse_list = []
    for err in env.errors:
        rmse = np.sqrt(np.mean(np.array(err) ** 2))
        rmse_list.append(rmse)

    env.disconnect()
    return rmse_list

# -----------------------------
# ì´ˆê¸° ë¬´ì‘ìœ„ Kd ì„¤ì •
kd_list = sorted(np.random.choice(np.arange(init_range[0], init_range[1]), size=robot_n, replace=False))
last_best_rmse = float('inf')

for iteration in range(max_iter):
    print(f"\nğŸ” Iteration {iteration+1} | Kp candidates: {kd_list}")
    rmses = run_simulation(kd_list, iteration)

    for i in range(robot_n):
        print(f"ë¡œë´‡ {i+1}: Kd = {kd_list[i]} â†’ í‰ê·  ì˜¤ì°¨ = {rmses[i]:.4f}")

    best_idx = int(np.argmin(rmses))
    best_kd = kd_list[best_idx]
    best_rmse = rmses[best_idx]

    print(f"\nâœ… Best Kp = {best_kd} (RMSE={best_rmse:.4f})")

    # ìˆ˜ë ´ ì¡°ê±´ í™•ì¸
    if abs(last_best_rmse - best_rmse) < conv_thresh:
        print("\nğŸ¯ ìˆ˜ë ´ ì¡°ê±´ ë§Œì¡± â†’ ìµœì  Kd íƒìƒ‰ ì¢…ë£Œ!")
        break
    last_best_rmse = best_rmse

    # ìƒˆë¡œìš´ Kp í›„ë³´ ìƒì„±
    kx = best_kd * kx_ratio
    kd_list = [int(best_kd + (i - robot_n//2) * (kx / (robot_n//2))) for i in range(robot_n)]

    # input("\nâ–¶ ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ë„˜ì–´ê°€ë ¤ë©´ Enter...")

print(f"\nğŸ ìµœì¢… ì„ íƒëœ Kd = {best_kd} (RMSE={best_rmse:.4f})")
np.save("saved_models/best_kd_value.npy", best_kd)
